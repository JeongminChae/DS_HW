{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "614bb340",
   "metadata": {},
   "source": [
    "Jeongmin Chae | 6022220672 | hw3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c6827327",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "import pandas as pd\n",
    "pd.set_option('display.max.colwidth', 100)\n",
    "pd.options.display.precision = 4\n",
    "import numpy as np\n",
    "from scipy.stats import bootstrap\n",
    "import bootstrapped.bootstrap as bs\n",
    "import bootstrapped.stats_functions as bs_stats\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "22c9d26e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimeSeriesClassification():\n",
    "    \n",
    "    def __init__(self,file_path_dic,tr_file_path_dic,ts_file_path_dic):\n",
    "        self.file_path_dic=file_path_dic\n",
    "        self.data=pd.DataFrame()\n",
    "        self.tr_data=pd.DataFrame()\n",
    "        self.ts_data=pd.DataFrame()\n",
    "        self.folder = ['bending1','bending2','cycling','lying','sitting','standing','walking']\n",
    "        self.columns = ['min1','max1','mean1','50%_1','std1','25%_1','75%_1',\n",
    "                                                  'min2','max2','mean2','50%_2','std2','25%_2','75%_2',\n",
    "                                                  'min3','max3','mean3','50%_3','std3','25%_3','75%_3',\n",
    "                                                  'min4','max4','mean4','50%_4','std4','25%_4','75%_4',\n",
    "                                                  'min5','max5','mean5','50%_5','std5','25%_5','75%_5',\n",
    "                                                  'min6','max6','mean6','50%_6','std6','25%_6','75%_6']\n",
    "        self.tr_file_path_dic=tr_file_path_dic\n",
    "        self.ts_file_path_dic=ts_file_path_dic\n",
    "        \n",
    "        \n",
    "    \n",
    "    \n",
    "    def feature_extraction(self):\n",
    "        \n",
    "      \n",
    "        new_data=[]\n",
    "        folder = self.folder\n",
    "\n",
    "        for i in range(len(self.folder)):\n",
    "            for j in range(len(self.file_path_dic[self.folder[i]])):\n",
    "                path=self.file_path_dic[self.folder[i]][j]\n",
    "                \n",
    "                    \n",
    "                df = pd.read_csv(path,skiprows=4,usecols=range(1,7))\n",
    "                df.columns=['a','b','c','d','e','f']\n",
    "                columns=['a','b','c','d','e','f']\n",
    "                data=pd.DataFrame()\n",
    "                for k in range(6):\n",
    "                    a=df.describe(include='all').loc[['min','max','mean','50%','std','25%','75%']][columns[k]]\n",
    "                    data=pd.concat([data,a],ignore_index=True)\n",
    "\n",
    "                new_data.append(np.array(data).reshape(1,len(data)))\n",
    "\n",
    "        new_data=np.array(new_data).reshape(len(new_data),len(columns)*7)\n",
    "        data=pd.DataFrame(new_data, columns=self.columns) \n",
    "        self.data=data\n",
    "        \n",
    "        print(\"Features are extracted.\")\n",
    "        print()\n",
    "        print(\"The number of data is {}\".format(data.shape[0]))\n",
    "        \n",
    "        return data\n",
    "    \n",
    "    \n",
    "    def train_test_split(self):\n",
    "        \n",
    "\n",
    "        tr_data=[]\n",
    "\n",
    "        for i in range(len(self.folder)):\n",
    "            for j in range(len(self.tr_file_path_dic[self.folder[i]])):\n",
    "                path=self.tr_file_path_dic[self.folder[i]][j]\n",
    "                df = pd.read_csv(path,skiprows=4,usecols=range(1,7))\n",
    "                df.columns=['a','b','c','d','e','f']\n",
    "                columns=['a','b','c','d','e','f']\n",
    "                data=pd.DataFrame()\n",
    "                for k in range(6):\n",
    "                    a=df.describe(include='all').loc[['min','max','mean','50%','std','25%','75%']][columns[k]]\n",
    "                    data=pd.concat([data,a],ignore_index=True)\n",
    "\n",
    "                tr_data.append(np.array(data).reshape(1,len(data)))\n",
    "\n",
    "        tr_data=np.array(tr_data).reshape(len(tr_data),len(columns)*7)\n",
    "        tr_data=pd.DataFrame(tr_data, columns=self.columns) \n",
    "        self.tr_data=tr_data\n",
    "        \n",
    "        \n",
    "        ts_data=[]\n",
    "\n",
    "        for i in range(len(self.folder)):\n",
    "            for j in range(len(self.ts_file_path_dic[self.folder[i]])):\n",
    "                path=self.ts_file_path_dic[self.folder[i]][j]\n",
    "                df = pd.read_csv(path,skiprows=4,usecols=range(1,7))\n",
    "                df.columns=['a','b','c','d','e','f']\n",
    "                columns=['a','b','c','d','e','f']\n",
    "                data=pd.DataFrame()\n",
    "                for k in range(6):\n",
    "                    a=df.describe(include='all').loc[['min','max','mean','50%','std','25%','75%']][columns[k]]\n",
    "                    data=pd.concat([data,a],ignore_index=True)\n",
    "\n",
    "                ts_data.append(np.array(data).reshape(1,len(data)))\n",
    "\n",
    "        ts_data=np.array(ts_data).reshape(len(ts_data),len(columns)*7)\n",
    "        ts_data=pd.DataFrame(ts_data, columns=self.columns) \n",
    "        self.ts_data=ts_data\n",
    "        \n",
    "        \n",
    "        print(\"Splited train and test data.\")\n",
    "        \n",
    "        return tr_data, ts_data\n",
    "        \n",
    "        \n",
    "        \n",
    "    def pick_three(self):\n",
    "        data=self.data\n",
    "        pick_three_data=data[['min1','max1','mean1',\n",
    "             'min2','max2','mean2',\n",
    "             'min3','max3','mean3',\n",
    "             'min4','max4','mean4',\n",
    "             'min5','max5','mean5',\n",
    "             'min6','max6','mean6']]\n",
    "        \n",
    "        print(\"Min, mean, and max are picked.\")\n",
    "        \n",
    "        return pick_three_data\n",
    "    \n",
    "    \n",
    "    def get_std(self):\n",
    "        \n",
    "        col_dic={}\n",
    "        columns=self.columns\n",
    "        for i in range(6):\n",
    "            col_dic[i]= columns[7*(i+1)-7:7*(i+1)]\n",
    "            \n",
    "\n",
    "        \n",
    "        std_list=[]\n",
    "        for n in range(6):\n",
    "            std=np.std(self.data[col_dic[n]])\n",
    "            std_list.append([std[0],std[1],std[2],std[3],std[4],std[5],std[6]])\n",
    "        std_list=pd.DataFrame(std_list, columns=['min', 'max', 'mean', '50%', 'std', '25%', '75%'],)\n",
    "        std_list.index=['avg_rss12','var_rss12','avg_rss13','var_rss13','avg_rss23','var_rss23']\n",
    "                        \n",
    "        return std_list\n",
    "                        \n",
    "    \n",
    "    def do_bootstrap(self):\n",
    "                        \n",
    "        columns = self.columns\n",
    "        (a,b)=self.data.shape\n",
    "        bs_std_list=[]\n",
    "        for i in range(b):\n",
    "            bs_std_list.append((bs.bootstrap(np.array(self.data[columns[i]]),stat_func=bs_stats.std, alpha=0.1)))\n",
    "   \n",
    "        \n",
    "        bs_std_list=pd.DataFrame(bs_std_list,columns=['std_value and range'])\n",
    "        bs_std_list.index = ['std_min1','std_max1','std_mean1','std_50%_1','std_std1','std_25%_1','std_75%_1',\n",
    "                             'std_min2','std_max2','std_mean2','std_50%_2','std_std2','std_25%_2','std_75%_2',\n",
    "                             'std_min3','std_max3','std_mean3','std_50%_3','std_std3','std_25%_3','std_75%_3',\n",
    "                             'std_min4','std_max4','std_mean4','std_50%_4','std_std4','std_25%_4','std_75%_4',\n",
    "                             'std_min5','std_max5','std_mean5','std_50%_5','std_std5','std_25%_5','std_75%_5',\n",
    "                             'std_min6','std_max6','std_mean6','std_50%_6','std_std6','std_25%_6','std_75%_6']\n",
    "                        \n",
    "        return bs_std_list "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f9e4b1ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path_dic={}\n",
    "file_path_dic['bending1']=['../data/AReM/bending1/dataset1.csv','../data/AReM/bending1/dataset2.csv','../data/AReM/bending1/dataset3.csv',\n",
    "                          '../data/AReM/bending1/dataset4.csv','../data/AReM/bending1/dataset5.csv','../data/AReM/bending1/dataset6.csv',\n",
    "                          '../data/AReM/bending1/dataset7.csv']\n",
    "file_path_dic['bending2']=['../data/AReM/bending2/dataset1.csv','../data/AReM/bending2/dataset2.csv','../data/AReM/bending2/dataset3.csv',\n",
    "                          '../data/AReM/bending2/dataset5.csv','../data/AReM/bending2/dataset6.csv']\n",
    "file_path_dic['cycling']=['../data/AReM/cycling/dataset1.csv','../data/AReM/cycling/dataset2.csv','../data/AReM/cycling/dataset3.csv',\n",
    "                          '../data/AReM/cycling/dataset4.csv','../data/AReM/cycling/dataset5.csv','../data/AReM/cycling/dataset6.csv','../data/AReM/cycling/dataset7.csv',\n",
    "                         '../data/AReM/cycling/dataset8.csv','../data/AReM/cycling/dataset9.csv','../data/AReM/cycling/dataset10.csv','../data/AReM/cycling/dataset11.csv','../data/AReM/cycling/dataset12.csv',\n",
    "                         '../data/AReM/cycling/dataset13.csv','../data/AReM/cycling/dataset14.csv','../data/AReM/cycling/dataset15.csv']\n",
    "file_path_dic['lying']=['../data/AReM/lying/dataset1.csv','../data/AReM/lying/dataset2.csv','../data/AReM/lying/dataset3.csv',\n",
    "                          '../data/AReM/lying/dataset4.csv','../data/AReM/lying/dataset5.csv','../data/AReM/lying/dataset6.csv','../data/AReM/lying/dataset7.csv',\n",
    "                         '../data/AReM/lying/dataset8.csv','../data/AReM/lying/dataset9.csv','../data/AReM/lying/dataset10.csv','../data/AReM/lying/dataset11.csv','../data/AReM/lying/dataset12.csv',\n",
    "                         '../data/AReM/lying/dataset13.csv','../data/AReM/lying/dataset14.csv','../data/AReM/lying/dataset15.csv']\n",
    "file_path_dic['sitting']=['../data/AReM/sitting/dataset1.csv','../data/AReM/sitting/dataset2.csv','../data/AReM/sitting/dataset3.csv',\n",
    "                          '../data/AReM/sitting/dataset4.csv','../data/AReM/sitting/dataset5.csv','../data/AReM/sitting/dataset6.csv','../data/AReM/sitting/dataset7.csv',\n",
    "                         '../data/AReM/sitting/dataset8.csv','../data/AReM/sitting/dataset9.csv','../data/AReM/sitting/dataset10.csv','../data/AReM/sitting/dataset11.csv','../data/AReM/sitting/dataset12.csv',\n",
    "                         '../data/AReM/sitting/dataset13.csv','../data/AReM/sitting/dataset14.csv','../data/AReM/sitting/dataset15.csv']\n",
    "file_path_dic['standing']=['../data/AReM/standing/dataset1.csv','../data/AReM/standing/dataset2.csv','../data/AReM/standing/dataset3.csv',\n",
    "                          '../data/AReM/standing/dataset4.csv','../data/AReM/standing/dataset5.csv','../data/AReM/standing/dataset6.csv','../data/AReM/standing/dataset7.csv',\n",
    "                         '../data/AReM/standing/dataset8.csv','../data/AReM/standing/dataset9.csv','../data/AReM/standing/dataset10.csv','../data/AReM/standing/dataset11.csv','../data/AReM/standing/dataset12.csv',\n",
    "                         '../data/AReM/standing/dataset13.csv','../data/AReM/standing/dataset14.csv','../data/AReM/standing/dataset15.csv']\n",
    "file_path_dic['walking']=['../data/AReM/walking/dataset1.csv','../data/AReM/walking/dataset2.csv','../data/AReM/walking/dataset3.csv',\n",
    "                          '../data/AReM/walking/dataset4.csv','../data/AReM/walking/dataset5.csv','../data/AReM/walking/dataset6.csv','../data/AReM/walking/dataset7.csv',\n",
    "                         '../data/AReM/walking/dataset8.csv','../data/AReM/walking/dataset9.csv','../data/AReM/walking/dataset10.csv','../data/AReM/walking/dataset11.csv','../data/AReM/walking/dataset12.csv',\n",
    "                         '../data/AReM/walking/dataset13.csv','../data/AReM/walking/dataset14.csv','../data/AReM/walking/dataset15.csv']\n",
    "\n",
    "tr_file_path_dic={}\n",
    "tr_file_path_dic['bending1']=['../data/AReM/bending1/dataset3.csv','../data/AReM/bending1/dataset4.csv','../data/AReM/bending1/dataset5.csv','../data/AReM/bending1/dataset6.csv',\n",
    "                                  '../data/AReM/bending1/dataset7.csv']\n",
    "tr_file_path_dic['bending2']=['../data/AReM/bending2/dataset3.csv','../data/AReM/bending2/dataset4.csv',\n",
    "                                  '../data/AReM/bending2/dataset5.csv','../data/AReM/bending2/dataset6.csv']\n",
    "tr_file_path_dic['cycling']=['../data/AReM/cycling/dataset4.csv','../data/AReM/cycling/dataset5.csv','../data/AReM/cycling/dataset6.csv','../data/AReM/cycling/dataset7.csv',\n",
    "                                 '../data/AReM/cycling/dataset8.csv','../data/AReM/cycling/dataset9.csv','../data/AReM/cycling/dataset10.csv','../data/AReM/cycling/dataset11.csv','../data/AReM/cycling/dataset12.csv',\n",
    "                                 '../data/AReM/cycling/dataset13.csv','../data/AReM/cycling/dataset14.csv','../data/AReM/cycling/dataset15.csv']\n",
    "tr_file_path_dic['lying']=['../data/AReM/lying/dataset4.csv','../data/AReM/lying/dataset5.csv','../data/AReM/lying/dataset6.csv','../data/AReM/lying/dataset7.csv',\n",
    "                                 '../data/AReM/lying/dataset8.csv','../data/AReM/lying/dataset9.csv','../data/AReM/lying/dataset10.csv','../data/AReM/lying/dataset11.csv','../data/AReM/lying/dataset12.csv',\n",
    "                                 '../data/AReM/lying/dataset13.csv','../data/AReM/lying/dataset14.csv','../data/AReM/lying/dataset15.csv']\n",
    "tr_file_path_dic['sitting']=['../data/AReM/sitting/dataset4.csv','../data/AReM/sitting/dataset5.csv','../data/AReM/sitting/dataset6.csv','../data/AReM/sitting/dataset7.csv',\n",
    "                                 '../data/AReM/sitting/dataset8.csv','../data/AReM/sitting/dataset9.csv','../data/AReM/sitting/dataset10.csv','../data/AReM/sitting/dataset11.csv','../data/AReM/sitting/dataset12.csv',\n",
    "                                 '../data/AReM/sitting/dataset13.csv','../data/AReM/sitting/dataset14.csv','../data/AReM/sitting/dataset15.csv']\n",
    "tr_file_path_dic['standing']=['../data/AReM/standing/dataset4.csv','../data/AReM/standing/dataset5.csv','../data/AReM/standing/dataset6.csv','../data/AReM/standing/dataset7.csv',\n",
    "                                 '../data/AReM/standing/dataset8.csv','../data/AReM/standing/dataset9.csv','../data/AReM/standing/dataset10.csv','../data/AReM/standing/dataset11.csv','../data/AReM/standing/dataset12.csv',\n",
    "                                 '../data/AReM/standing/dataset13.csv','../data/AReM/standing/dataset14.csv','../data/AReM/standing/dataset15.csv']\n",
    "tr_file_path_dic['walking']=['../data/AReM/walking/dataset4.csv','../data/AReM/walking/dataset5.csv','../data/AReM/walking/dataset6.csv','../data/AReM/walking/dataset7.csv',\n",
    "                                 '../data/AReM/walking/dataset8.csv','../data/AReM/walking/dataset9.csv','../data/AReM/walking/dataset10.csv','../data/AReM/walking/dataset11.csv','../data/AReM/walking/dataset12.csv',\n",
    "                                 '../data/AReM/walking/dataset13.csv','../data/AReM/walking/dataset14.csv','../data/AReM/walking/dataset15.csv']\n",
    "\n",
    "ts_file_path_dic={}\n",
    "ts_file_path_dic['bending1']=['../data/AReM/bending1/dataset1.csv','../data/AReM/bending1/dataset2.csv']\n",
    "ts_file_path_dic['bending2']=['../data/AReM/bending2/dataset1.csv','../data/AReM/bending2/dataset2.csv']                   \n",
    "ts_file_path_dic['cycling']=['../data/AReM/cycling/dataset1.csv','../data/AReM/cycling/dataset2.csv','../data/AReM/cycling/dataset3.csv']                   \n",
    "ts_file_path_dic['lying']=['../data/AReM/lying/dataset1.csv','../data/AReM/lying/dataset2.csv','../data/AReM/lying/dataset3.csv']                \n",
    "ts_file_path_dic['sitting']=['../data/AReM/sitting/dataset1.csv','../data/AReM/sitting/dataset2.csv','../data/AReM/sitting/dataset3.csv']            \n",
    "ts_file_path_dic['standing']=['../data/AReM/standing/dataset1.csv','../data/AReM/standing/dataset2.csv','../data/AReM/standing/dataset3.csv']\n",
    "ts_file_path_dic['walking']=['../data/AReM/walking/dataset1.csv','../data/AReM/walking/dataset2.csv','../data/AReM/walking/dataset3.csv']\n",
    "                               \n",
    "\n",
    "TSC=TimeSeriesClassification(file_path_dic,tr_file_path_dic,ts_file_path_dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4470903a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1.b\n",
    "tr_data, ts_data = TSC.train_test_split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4e046f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1.c.i\n",
    "\n",
    "print(\"\"\"\n",
    "\n",
    "Usually, in time-series classification problem, \\n\n",
    "means, variance, maximum value, minimum value, quantile, auto-correlation and variance are considered.\n",
    "\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c585648",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1.c.ii\n",
    "data = TSC.feature_extraction()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e7cc2b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1.c.iii\n",
    "std_list = TSC.get_std()\n",
    "std_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a642aea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1.c.iii\n",
    "bs_std_list=TSC.do_bootstrap()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3831fc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1.c.iv\n",
    "\n",
    "pick_three_data=TSC.pick_three()\n",
    "\n",
    "\n",
    "print(\"\"\"\n",
    "\n",
    "I picked min, mean, and max for each variable.\n",
    "\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ac15a06",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0b1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
